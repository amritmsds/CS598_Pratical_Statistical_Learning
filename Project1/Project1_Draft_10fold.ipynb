{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sOPurlY9YXlU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1skJ5NpGYXlW"
      },
      "source": [
        "**References**\n",
        "> https://www.kaggle.com/code/bextuychiev/lasso-regression-with-pipelines-tutorial\n",
        "\n",
        "> https://www.kaggle.com/code/carlosdg/xgboost-with-scikit-learn-pipeline-gridsearchcv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-zHfFHWQbH9F"
      },
      "outputs": [],
      "source": [
        "def categorical_variable_transform(train_df, test_df):\n",
        "    # IMPORTANT:\n",
        "    # The test_dataframe needs to use the encoder from the trainng_dataframe, because some categories might be\n",
        "    # missing in the test data\n",
        "\n",
        "    categorical_feature_set = [feature for feature in train_df.columns if train_df[feature].dtypes=='object']\n",
        "\n",
        "    for feature in categorical_feature_set:\n",
        "        encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "        train_category_matrix = [[element] for element in train_df[feature]]\n",
        "        test_category_matrix = [[element] for element in test_df[feature]]\n",
        "\n",
        "        encoder.fit(train_category_matrix)\n",
        "        train_df_hot_code = pd.DataFrame(encoder.transform(train_category_matrix).toarray())\n",
        "        test_df_hot_code = pd.DataFrame(encoder.transform(test_category_matrix).toarray())\n",
        "\n",
        "        train_df_hot_code.columns = [feature + '_' + str(c) for c in train_df_hot_code.columns]\n",
        "        test_df_hot_code.columns = [feature + '_' + str(c) for c in test_df_hot_code.columns]\n",
        "\n",
        "\n",
        "        # Replace the original feature with one-hot encoded feature\n",
        "        train_df.drop(columns=feature, inplace=True)\n",
        "        train_df = pd.concat([train_df, train_df_hot_code], axis=1)\n",
        "        test_df.drop(columns=feature, inplace=True)\n",
        "        test_df = pd.concat([test_df, test_df_hot_code], axis=1)\n",
        "\n",
        "\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-UOr6oOGZlIP"
      },
      "outputs": [],
      "source": [
        "def preprocessing(data_folder):\n",
        "  df_train = pd.read_csv(os.path.join(data_folder, \"train.csv\"))\n",
        "  df_test_x = pd.read_csv(os.path.join(data_folder, \"test.csv\"))\n",
        "  df_test_y = pd.read_csv(os.path.join(data_folder, \"test_y.csv\"))\n",
        "\n",
        "  df_train_y = pd.DataFrame()\n",
        "  df_train_y['Sale_Price'] = df_train['Sale_Price'].copy()\n",
        "  df_train_x = df_train.drop(columns=['PID', 'Sale_Price'])\n",
        "  df_test_x.drop(columns=['PID'], inplace=True)\n",
        "  df_test_y.drop(columns=['PID'], inplace=True)\n",
        "\n",
        "  # Impute missing values in \"Garage_Yr_Blt\" variable with 0\n",
        "  df_train_x['Garage_Yr_Blt'].fillna(0, inplace=True)\n",
        "  df_test_x['Garage_Yr_Blt'].fillna(0, inplace=True)\n",
        "\n",
        "  # The following features are either highly imbalanced or not informative\n",
        "  remove_features_set = ['Condition_2', 'Heating', 'Latitude', 'Longitude', 'Low_Qual_Fin_SF',\n",
        "                        'Misc_Feature','Pool_Area','Pool_QC','Roof_Matl','Street','Utilities']\n",
        "  df_train_x.drop(columns=remove_features_set, inplace=True)\n",
        "  df_test_x.drop(columns=remove_features_set, inplace=True)\n",
        "\n",
        "  winsor_features_set = ['BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Enclosed_Porch', 'First_Flr_SF',\n",
        "                  'Garage_Area', 'Gr_Liv_Area', 'Lot_Area', 'Lot_Frontage','Mas_Vnr_Area',\n",
        "                  'Misc_Val', 'Open_Porch_SF', 'Screen_Porch', 'Second_Flr_SF', 'Three_season_porch',\n",
        "                  'Total_Bsmt_SF', 'Wood_Deck_SF']\n",
        "  for val in winsor_features_set:\n",
        "    upper_limit1 = df_train[val].quantile(0.974)\n",
        "    df_train_x[val] = df_train_x[val].apply(lambda x: upper_limit1 if x > upper_limit1 else x)\n",
        "    upper_limit2 = df_test_x[val].quantile(0.974)\n",
        "    df_test_x[val] = df_test_x[val].apply(lambda x: upper_limit2 if x > upper_limit2 else x)\n",
        "\n",
        "  # Treating the two features \"Mo_Sold\" (1~12), and \"Year_Sold\" (2006~2010) as categorical\n",
        "  # variables can improve model performance\n",
        "  df_train_x['Mo_Sold'] = df_train_x['Mo_Sold'].values.astype('object')\n",
        "  df_test_x['Mo_Sold'] = df_test_x['Mo_Sold'].values.astype('object')\n",
        "  df_train_x['Year_Sold'] = df_train_x['Year_Sold'].values.astype('object')\n",
        "  df_test_x['Year_Sold'] = df_test_x['Year_Sold'].values.astype('object')\n",
        "\n",
        "  df_train_x_trans, df_test_x_trans =  categorical_variable_transform(df_train_x, df_test_x)\n",
        "\n",
        "  # Log-scale sale_price\n",
        "  df_train_y['Sale_Price'] =  df_train_y['Sale_Price'].apply(lambda y: np.log(y))\n",
        "  df_test_y['Sale_Price'] =  df_test_y['Sale_Price'].apply(lambda y: np.log(y))\n",
        "\n",
        "  return df_train_x_trans, df_test_x_trans, df_train_y, df_test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xsBX4Rbdfv5l"
      },
      "outputs": [],
      "source": [
        "best_alpha = 0.0026048905108264305"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8gf-eXWqbb6u"
      },
      "outputs": [],
      "source": [
        "def lasso_rmse(df_train_x_trans, df_test_x_trans, df_train_y, df_test_y, best_alpha):\n",
        "  best_lasso = Lasso(fit_intercept=True, random_state=0, alpha=best_alpha, max_iter=10000)\n",
        "  best_lasso_pipeline = Pipeline(steps=[(\"scalar\",StandardScaler()), (\"lasso\", best_lasso)])\n",
        "\n",
        "  best_lasso_pipeline.fit(df_train_x_trans , df_train_y)\n",
        "\n",
        "  lasso_train_predict = best_lasso_pipeline.predict(df_train_x_trans)\n",
        "  lasso_test_predict = best_lasso_pipeline.predict(df_test_x_trans)\n",
        "\n",
        "  lasso_rmse_train = np.sqrt(np.mean((lasso_train_predict - np.squeeze(df_train_y.values))**2))\n",
        "  lasso_rmse_test = np.sqrt(np.mean((lasso_test_predict - np.squeeze(df_test_y.values))**2))\n",
        "  return lasso_rmse_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ECi96zyHgEMm"
      },
      "outputs": [],
      "source": [
        "max_depth = 2\n",
        "n_estimators = 420"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5oGvkieUgMR3"
      },
      "outputs": [],
      "source": [
        "def XGBoost_rmse(df_train_x_trans, df_test_x_trans, df_train_y, df_test_y, max_depth, n_estimators):\n",
        "  best_xgb = XGBRegressor(max_depth=max_depth, n_estimators=400)\n",
        "  best_xgb_pipeline = Pipeline(steps=[(\"scalar\",StandardScaler()), (\"xgb\", best_xgb)])\n",
        "\n",
        "  best_xgb_pipeline.fit(df_train_x_trans , df_train_y)\n",
        "  xgb_train_predict = best_xgb_pipeline.predict(df_train_x_trans)\n",
        "  xgb_test_predict = best_xgb_pipeline.predict(df_test_x_trans)\n",
        "  xgb_rmse_train = np.sqrt(np.mean((xgb_train_predict - np.squeeze(df_train_y.values))**2))\n",
        "  xgb_rmse_test = np.sqrt(np.mean((xgb_test_predict - np.squeeze(df_test_y.values))**2))\n",
        "  return xgb_rmse_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrfLdNiDaLeb",
        "outputId": "42e9b98e-a483-4eb1-d00c-c013e7934409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13.214696884155273\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "root = '/Users/richardxu/Dropbox/UIUC_CS598_Statistical_Learning/Project1/proj1/fold'\n",
        "lasso_rmse_list = []\n",
        "tree_rmse_list = []\n",
        "start_time = time.time()\n",
        "for i in range(1, 11):\n",
        "  df_train_x_trans, df_test_x_trans, df_train_y, df_test_y = preprocessing(root+str(i))\n",
        "  lasso_rmse_list.append(lasso_rmse(df_train_x_trans, df_test_x_trans, df_train_y, df_test_y, best_alpha))\n",
        "  tree_rmse_list.append(XGBoost_rmse(df_train_x_trans, df_test_x_trans, df_train_y, df_test_y, max_depth, n_estimators))\n",
        "end_time = time.time()\n",
        "print(end_time - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC4mop3vkWhn",
        "outputId": "818306a2-62d6-48fb-da5e-7cf9ad0e1282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.1240\n",
            "0.1176\n",
            "0.1222\n",
            "0.1296\n",
            "0.1124\n",
            "0.1338\n",
            "0.1269\n",
            "0.1203\n",
            "0.1304\n",
            "0.1235\n",
            "\n",
            "0.1163\n",
            "0.1226\n",
            "0.1187\n",
            "0.1242\n",
            "0.1181\n",
            "0.1356\n",
            "0.1325\n",
            "0.1288\n",
            "0.1317\n",
            "0.1321\n"
          ]
        }
      ],
      "source": [
        "for rmse in lasso_rmse_list:\n",
        "  print(\"%.4f\" % rmse)\n",
        "print()\n",
        "for rmse in tree_rmse_list:\n",
        "  print(\"%.4f\" % rmse)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
