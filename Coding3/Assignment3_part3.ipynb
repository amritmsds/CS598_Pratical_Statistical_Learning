{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Ridgeless and double descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So far in our course, we’ve utilized the U-shaped bias-variance trade-off curve as a pivotal tool for model selection. This has aided us in methodologies such as ridge/lasso regression, tree pruning, and smoothing splines, among others.\n",
    "\n",
    "A key observation is that when a model interpolates training data to the extent that the Residual Sum of Squares (RSS) equals zero, it’s typically a red flag signaling overfitting. Such models are anticipated to perform inadequately when presented with new, unseen data. \n",
    "\n",
    "> However, in modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered overfitted, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. ([Belkin et al. 2019](https://liangfgithub.github.io/Coding/DoubleDescent_PNAS_2019.pdf))\n",
    "\n",
    "In this assignment, we will use Ridgeless to illustrate the double descent phenomenon. Our setup is similar to, but not the same as, [Section 8 in Hastie (2020)](https://liangfgithub.github.io/Coding/Ridge_Hastie_2020.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the dataset used in Coding 2 Part I? It consisted of 506 rows (i.e., n = 506) and 14 columns: *Y*, *X1* through *X13*.\n",
    "\n",
    "Based on this dataset, we have formed <u>Coding3_dataH.csv</u>, which is structured as follows:\n",
    "\n",
    "- It contains 506 rows, corresponding to *n* = 506.\n",
    "- There are 241 columns in total. The first column represents *Y* . The subsequent 240 columns relate to the NCS basis functions for each of the 13 X variables. The number of knots are individually determined for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Ridgeless function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridgeless least squares can be equated with principal component regression (PCR) when all principal components are employed. For our simulation study, we’ll employ the PCR version with the **scale = FALSE** option, implying that we’ll center each column of the design matrix from the training data without scaling.\n",
    "\n",
    "Your task is to write a function that accepts training and test datasets and returns the training and test errors of the ridgeless estimator. For both datasets, the initial column represents the response vector *Y*.\n",
    "\n",
    "- You can use R/Python packages or built-in functions for PCA/SVD, but you are not allowed to use packages or functions tailored for linear regression, PCR, or ridge regression.\n",
    "\n",
    "- Post PCA/SVD, you’ll notice that the updated design matrix comprises orthogonal columns. This allows for the calculation of least squares coefficients through simple matrix multiplication, eliminating the need for matrix inversion.\n",
    "\n",
    "- For computation stability, you need to exclude directions with extremely small eigenvalues (in PCA) or singular values (in SVD). As a reference, consider setting **eps = 1e-10** as the threshold for singular values.\n",
    "\n",
    "- Although training errors aren’t a requisite for our simulation, I recommend including them in the ridgeless output. This serves as a useful debugging tool. Ideally, your training error should align with the RSS derived from a standard linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridgeless_function(training_data:np.ndarray, testing_data:np.ndarray) -> float:\n",
    "    X_train = training_data[:, 1:]\n",
    "    Y_train = training_data[:, 0]\n",
    "    X_test = testing_data[:, 1:]\n",
    "    Y_test = testing_data[:, 0]\n",
    "    \n",
    "    scaler = StandardScaler(with_mean=True, with_std=False)\n",
    "    pca = PCA()\n",
    "\n",
    "    pipeline = Pipeline([('scaling', scaler), ('pca', pca)])\n",
    "    pipeline.fit(X_train)\n",
    "    X_train = pipeline.transform(X_train)  # X_train changes to XtX shape\n",
    "    X_train = X_train[:, pca.singular_values_>1e-10]   # setting threshold for comoputational stability\n",
    "    coefs =Y_train.T @ X_train / np.sum(X_train**2, axis=0)\n",
    "    b0 = np.mean(Y_train)\n",
    "\n",
    "    X_test = pipeline.transform(X_test)   # X_test changes to XtX covariance shape\n",
    "    X_test = X_test[:, pca.singular_values_>1e-10]\n",
    "\n",
    "\n",
    "    preds = X_test @ coefs.T + b0\n",
    "    rmse = np.log(np.sqrt(np.mean((Y_test-preds)**2)))\n",
    "\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Simulation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the procedure below for *T* = 30 times.\n",
    "\n",
    "In each iteration,\n",
    "- Randomly partition the data into training (25%) and test (75%).\n",
    "- Calculate and log the test error from the ridgeless method using the first *d* columns of **myData**, where *d* ranges from 6 to 241. Keep in mind that the number of regression parameters spans from 5 to 240 because the first column represents *Y*.\n",
    "\n",
    "This will result in recording 236 test errors per iteration. These errors are the averaged mean squared errors based on the test data. One practical way to manage this data would be to maintain a matrix of dimensions 30-by-236 to house the test errors derived from this simulation study.\n",
    "\n",
    "**Graphical display**: \n",
    "Plot the median of the test errors (collated over the 30 iterations) in **log scale** against the count of regression parameters, which spans from 5 to 240."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"Coding3_dataH.csv\", header=None)\n",
    "Ydata = Data.loc[:, 0].values\n",
    "Xdata = Data.loc[:, 1:241].values\n",
    "\n",
    "X_train = Xdata[:125, :]\n",
    "Y_train = Ydata[:125]\n",
    "X_test = Xdata[125:, :]\n",
    "Y_test = Ydata[125:]\n",
    "\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=False)\n",
    "pca = PCA()\n",
    "\n",
    "pipeline = Pipeline([('scaling', scaler), ('pca', pca)])\n",
    "pipeline.fit(X_train)\n",
    "X_train = pipeline.transform(X_train)  #125 * 125\n",
    "X_train = X_train[:, pca.singular_values_>1e-10]\n",
    "coefs =Y_train.T @ X_train / np.sum(X_train**2, axis=0)\n",
    "b0 = np.mean(Y_train)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "X_test = X_test[:, pca.singular_values_>1e-10]\n",
    "\n",
    "\n",
    "preds = X_test @ coefs.T + b0\n",
    "rmse = np.sqrt(np.mean((Y_test-preds)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = Data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 241)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9407843722169447"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(cv_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 240)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.059197791963998"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
