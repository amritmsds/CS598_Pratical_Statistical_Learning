{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Bayes rule\n",
    "1. Implement the Bayes rule. Your implementation should meet the following requirements:\n",
    "   - Do not use explicit loops over the test sample size (10,000 or 5,000). \n",
    "   - You are allowed to use loops over the number of centers (10 or 20), although you can avoid all loops.\n",
    "2. Test your code with the test data you just generated. (Note that you do not need training data for the Bayes rule.) Report your results (on the test data) as a 2-by-2 table. \n",
    "\n",
    "The Bayes rule for binary classification (under the zero-one loss), as derived in class, is: predict $Y$ to be 1, if \n",
    "\n",
    "$$\n",
    "P(Y = 1 \\mid X = x) \\ge P(Y = 0 \\mid X=x), \n",
    "$$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$$ \\frac{P(Y = 1 \\mid X = x)}{P(Y = 0 \\mid X=x)} \\ge 1.$$\n",
    "\n",
    "Following the data generation process, we have \n",
    "$$ \\displaystyle  \\frac{P(Y=1\\mid X=x)}{P(Y=0\\mid X=x)}=\\frac{P(Y=1) \\cdot P(X=x\\mid Y=1)}{P(Y=0) \\cdot P(X=x\\mid Y=0)} $$\n",
    "$$\\displaystyle =\\frac{(1/2)\\cdot 10^{-1}\\sum_{l=1}^{10}(2\\pi s^2)^{-1}\\exp\\left(-\\lVert\\mathbf{x}-\\mathbf{m}_{1l}\\rVert^2/(2s^2)\\right)}{(1/2)\\cdot 10^{-1}\\sum_{l=1}^{10}(2\\pi s^2)^{-1}\\exp\\left(-\\lVert\\mathbf{x}-\\mathbf{m}_{0l}\\rVert^2/(2s^2)\\right)} $$\n",
    "$$\\displaystyle =\\frac{\\sum_{l=1}^{10}\\exp\\left(-\\lVert\\mathbf{x}-\\mathbf{m}_{1l}\\rVert^2/(2s^2)\\right)}{\\sum_{l=1}^{10}\\exp\\left(-\\lVert\\mathbf{x}-\\mathbf{m}_{0l}\\rVert^2/(2s^2)\\right)}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prob(data, mu):\n",
    "    result = np.linalg.norm(data[:, None] - mu, axis=2) ** 2\n",
    "    result = np.sum(np.exp(-result / (2 * s ** 2)), axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_rule(data, mu0, mu1):\n",
    "    return np.where(calculate_prob(data, mu1) >= calculate_prob(data, mu0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bayes = np.where(calculate_prob(X_testing, mu_k1) >= calculate_prob(X_testing, mu_k0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3855  615]\n",
      " [1145 4385]]\n"
     ]
    }
   ],
   "source": [
    "print(calc_confusion_matrix(y_pred_bayes, Y_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
